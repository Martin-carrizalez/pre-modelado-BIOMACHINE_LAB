{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed831abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "PASO 10: AN√ÅLISIS AVANZADO Y VALIDACI√ìN FINAL\n",
      "================================================================================\n",
      "\n",
      "‚úì SHAP disponible\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 1: CARGA Y PREPARACI√ìN\n",
      "================================================================================\n",
      "\n",
      "Cargando datasets...\n",
      "Convirtiendo a float64...\n",
      "‚úì Dataset A: (538, 42)\n",
      "‚úì Dataset B: (538, 19)\n",
      "\n",
      "Aplicando SMOTE...\n",
      "‚úì Train=578, Test=108\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 2: ENTRENAMIENTO DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "1. Logistic Regression...\n",
      "2. Random Forest con RFE (30 features)...\n",
      "3. XGBoost (30 features)...\n",
      "3b. XGBoost completo (41 features, solo para SHAP)...\n",
      "4. K-Nearest Neighbors...\n",
      "‚úì Modelos entrenados\n",
      "\n",
      "NOTA: Ensemble eliminado (causa conflictos sklearn/xgboost y no mejora resultados)\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 3: M√âTRICAS CL√çNICAS EXTENDIDAS\n",
      "================================================================================\n",
      "\n",
      "              Model  TN  FP  FN  TP  Accuracy  Precision (PPV)  Recall (Sensibilidad)  Especificidad  F1-Score      NPV       LR+      LR-  ROC-AUC\n",
      "Logistic Regression  64   9   3  32  0.888889         0.780488               0.914286       0.876712  0.842105 0.955224  7.415873 0.097768 0.948337\n",
      "Random Forest (30f)  70   3   5  30  0.925926         0.909091               0.857143       0.958904  0.882353 0.933333 20.857143 0.148980 0.947162\n",
      "      XGBoost (41f)  69   4   4  31  0.925926         0.885714               0.885714       0.945205  0.885714 0.945205 16.164286 0.120911 0.948337\n",
      "      XGBoost (30f)  70   3   5  30  0.925926         0.909091               0.857143       0.958904  0.882353 0.933333 20.857143 0.148980 0.951468\n",
      "                KNN  61  12   7  28  0.824074         0.700000               0.800000       0.835616  0.746667 0.897059  4.866667 0.239344 0.905088\n",
      "\n",
      "‚úì Guardado: metricas_clinicas_extendidas.csv\n",
      "\n",
      "NOTA: XGBoost evaluado con 41 features (completo) y 30 features (RFE)\n",
      "\n",
      "INTERPRETACI√ìN CL√çNICA:\n",
      "\n",
      "Sensibilidad (Recall): % de casos SOP detectados correctamente\n",
      "  ‚Üí Alto = Menos falsos negativos (no se pierden casos)\n",
      "\n",
      "Especificidad: % de No-SOP identificados correctamente\n",
      "  ‚Üí Alto = Menos falsos positivos (menos alarmas falsas)\n",
      "\n",
      "PPV (Precision): Si predice SOP, ¬øprobabilidad real?\n",
      "  ‚Üí Alto = Predicci√≥n SOP confiable\n",
      "\n",
      "NPV: Si predice No-SOP, ¬øprobabilidad real?\n",
      "  ‚Üí Alto = Predicci√≥n negativa confiable\n",
      "\n",
      "LR+ (Likelihood Ratio +): >10 excelente, >5 muy bueno\n",
      "LR- (Likelihood Ratio -): <0.1 excelente, <0.2 muy bueno\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 4: SHAP EXPLICABILIDAD\n",
      "================================================================================\n",
      "\n",
      "Calculando SHAP para XGBoost (41 features)...\n",
      "(Esto puede tardar 2-3 minutos)\n",
      "\n",
      "‚úì shap_xgboost_summary.png\n",
      "‚úì shap_xgboost_beeswarm.png\n",
      "‚úì shap_importance_xgboost.csv\n",
      "\n",
      "TOP 10 VARIABLES (XGBoost SHAP):\n",
      "                  Feature  SHAP_Mean_Abs\n",
      "        Num Fol√≠culos (D)       1.733894\n",
      "       Aumento Peso (S/N)       0.715394\n",
      "  Crecimiento Vello (S/N)       0.644033\n",
      "        Num Fol√≠culos (I)       0.616893\n",
      "Oscurecimiento Piel (S/N)       0.536749\n",
      "              Ciclo (R/I)       0.519273\n",
      "              AMH (ng/mL)       0.319128\n",
      "               Acn√© (S/N)       0.307529\n",
      "    Duraci√≥n Ciclo (d√≠as)       0.289903\n",
      "      Comida R√°pida (S/N)       0.203337\n",
      "\n",
      "Calculando SHAP para Random Forest...\n",
      "(Esto puede tardar 3-5 minutos)\n",
      "\n",
      "‚úì shap_rf_summary.png\n",
      "‚úì shap_rf_beeswarm.png\n",
      "‚ùå Error en SHAP: Per-column arrays must each be 1-dimensional\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 5: COMPARACI√ìN DE MODELOS\n",
      "================================================================================\n",
      "\n",
      "              Model  Accuracy  Precision   Recall  F1-Score  ROC-AUC\n",
      "Logistic Regression  0.888889   0.780488 0.914286  0.842105 0.948337\n",
      "Random Forest (30f)  0.925926   0.909091 0.857143  0.882353 0.947162\n",
      "      XGBoost (41f)  0.925926   0.885714 0.885714  0.885714 0.948337\n",
      "      XGBoost (30f)  0.925926   0.909091 0.857143  0.882353 0.951468\n",
      "                KNN  0.824074   0.700000 0.800000  0.746667 0.905088\n",
      "\n",
      "‚úì Guardado: modelos_comparison.csv\n",
      "\n",
      "üèÜ MEJOR MODELO EN TEST SET: XGBoost (41f) (F1=0.8857)\n",
      "\n",
      "================================================================================\n",
      "SECCI√ìN 6: VALIDACI√ìN CRUZADA REPETIDA (5√ó3)\n",
      "================================================================================\n",
      "\n",
      "Configuraci√≥n: 5-Fold √ó 3 repeticiones = 15 evaluaciones\n",
      "(Esto puede tardar 5-10 minutos)\n",
      "\n",
      "Validando Logistic Regression...\n",
      "  ‚úì F1 = 0.9066 ¬± 0.0205\n",
      "Validando Random Forest (30f)...\n",
      "  ‚úì F1 = 0.9283 ¬± 0.0249\n",
      "Validando XGBoost (30f)...\n",
      "  ‚úì F1 = 0.9207 ¬± 0.0206\n",
      "Validando KNN...\n",
      "  ‚úì F1 = 0.9091 ¬± 0.0291\n",
      "\n",
      "RESULTADOS VALIDACI√ìN CRUZADA REPETIDA:\n",
      "\n",
      "              Model  Accuracy_mean  Accuracy_std  Precision_mean  Precision_std  Recall_mean  Recall_std  F1_mean   F1_std  ROC_AUC_mean  ROC_AUC_std\n",
      "Logistic Regression       0.906602      0.020123        0.907392       0.034227     0.907804    0.037472 0.906645 0.020504      0.969287     0.012441\n",
      "Random Forest (30f)       0.929690      0.023463        0.943114       0.027941     0.915971    0.047365 0.928321 0.024870      0.981595     0.009253\n",
      "      XGBoost (30f)       0.921014      0.020124        0.923864       0.031126     0.919379    0.039031 0.920728 0.020593           NaN          NaN\n",
      "                KNN       0.908916      0.028770        0.906349       0.028128     0.912462    0.037905 0.909109 0.029146      0.970046     0.015317\n",
      "\n",
      "‚úì Guardado: validacion_repetida_results.csv\n",
      "\n",
      "‚úì Guardado: validacion_repetida_intervals.png\n",
      "\n",
      "================================================================================\n",
      "REPORTE FINAL Y RECOMENDACIONES\n",
      "================================================================================\n",
      "\n",
      "üèÜ MODELO RECOMENDADO:\n",
      "   Random Forest (30f)\n",
      "   F1-Score: 0.9283 ¬± 0.0249\n",
      "\n",
      "üìä M√âTRICAS CL√çNICAS (Test Set):\n",
      "   Sensibilidad: 85.7%\n",
      "   Especificidad: 95.9%\n",
      "   PPV: 90.9%\n",
      "   NPV: 93.3%\n",
      "   LR+: 20.86\n",
      "   LR-: 0.149\n",
      "\n",
      "üìã RECOMENDACIONES PARA TESIS/PAPER:\n",
      "\n",
      "1. MODELO FINAL:\n",
      "   ‚Üí Usar Random Forest (30f)\n",
      "   ‚Üí Reportar F1 = 0.9283 ¬± 0.0249\n",
      "   ‚Üí Mencionar validaci√≥n cruzada repetida 5√ó3\n",
      "\n",
      "2. M√âTRICAS CL√çNICAS A REPORTAR:\n",
      "   ‚Üí Sensibilidad: 85.7% (detecta casos SOP)\n",
      "   ‚Üí Especificidad: 95.9% (identifica No-SOP)\n",
      "   ‚Üí PPV: 90.9% (confianza predicci√≥n positiva)\n",
      "   ‚Üí NPV: 93.3% (confianza predicci√≥n negativa)\n",
      "\n",
      "3. EXPLICABILIDAD:\n",
      "   ‚Üí Usar gr√°ficos SHAP beeswarm para interpretaci√≥n\n",
      "   ‚Üí Discutir top 5-10 variables m√°s importantes\n",
      "   ‚Üí Validar coherencia cl√≠nica con criterios Rotterdam\n",
      "\n",
      "4. VALIDACI√ìN:\n",
      "   ‚Üí Mencionar robustez (validaci√≥n repetida 15 evaluaciones)\n",
      "   ‚Üí Reportar intervalos de confianza\n",
      "   ‚Üí Destacar reducci√≥n dimensional (42 ‚Üí 30 features)\n",
      "\n",
      "‚úì Reporte guardado: reporte_final_paso10.json\n",
      "\n",
      "================================================================================\n",
      "ARCHIVOS GENERADOS\n",
      "================================================================================\n",
      "\n",
      "üìÅ M√âTRICAS Y RESULTADOS:\n",
      "  1. metricas_clinicas_extendidas.csv\n",
      "  2. modelos_comparison.csv\n",
      "  3. validacion_repetida_results.csv\n",
      "  4. shap_importance_xgboost.csv\n",
      "  5. shap_importance_rf.csv\n",
      "\n",
      "üìä VISUALIZACIONES:\n",
      "  6. shap_xgboost_summary.png\n",
      "  7. shap_xgboost_beeswarm.png\n",
      "  8. shap_rf_summary.png\n",
      "  9. shap_rf_beeswarm.png\n",
      "  10. validacion_repetida_intervals.png\n",
      "\n",
      "üìÑ REPORTES:\n",
      "  11. reporte_final_paso10.json\n",
      "\n",
      "================================================================================\n",
      "‚úÖ PASO 10 COMPLETADO EXITOSAMENTE\n",
      "================================================================================\n",
      "\n",
      "üéâ AN√ÅLISIS COMPLETO Y VALIDADO\n",
      "\n",
      "Has completado:\n",
      "  ‚úì M√©tricas cl√≠nicas extendidas (Sens/Spec/PPV/NPV/LR)\n",
      "  ‚úì Explicabilidad SHAP (XGBoost + Random Forest)\n",
      "  ‚úì Comparaci√≥n completa de modelos\n",
      "  ‚úì Validaci√≥n cruzada repetida (robustez demostrada)\n",
      "  ‚úì Reporte final completo\n",
      "\n",
      "Tu proyecto est√° listo para:\n",
      "  ‚Üí Defensa de tesis ‚úÖ\n",
      "  ‚Üí Publicaci√≥n cient√≠fica ‚úÖ\n",
      "  ‚Üí Presentaci√≥n a comit√© biom√©dico ‚úÖ\n",
      "\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x800 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"\n",
    "================================================================================\n",
    "PASO 10: AN√ÅLISIS AVANZADO Y VALIDACI√ìN FINAL - VERSION COMPLETA\n",
    "================================================================================\n",
    "\n",
    "Proyecto: Predicci√≥n de S√≠ndrome de Ovario Poliqu√≠stico (SOP)\n",
    "Instituci√≥n: Cl√∫ster de Ingenier√≠a Biom√©dica del Estado de Jalisco\n",
    "Fecha: Noviembre 2025\n",
    "\n",
    "INCLUYE:\n",
    "- M√©tricas cl√≠nicas extendidas (Sens/Spec/PPV/NPV/LR+/LR-)\n",
    "- SHAP explicabilidad (XGBoost + Random Forest)\n",
    "- Comparaci√≥n de modelos (LR, RF, XGBoost, KNN)\n",
    "- Validaci√≥n cruzada repetida (5√ó3)\n",
    "- Reporte final JSON\n",
    "\n",
    "NOTA: Ensemble eliminado (conflictos sklearn/xgboost, no mejora resultados)\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, StratifiedKFold, RepeatedStratifiedKFold,\n",
    "    cross_validate, GridSearchCV\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_OK = True\n",
    "except ImportError:\n",
    "    SHAP_OK = False\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PASO 10: AN√ÅLISIS AVANZADO Y VALIDACI√ìN FINAL\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "if SHAP_OK:\n",
    "    print(\"‚úì SHAP disponible\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SHAP no disponible (pip install shap)\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 1: CARGA Y PREPARACI√ìN DE DATOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 1: CARGA Y PREPARACI√ìN\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "PATH_DATASET_A = '../documentos_generados/PCOS_data_transformado.csv'\n",
    "PATH_DATASET_B = 'PCOS_data_FINAL_sin_multicolinealidad.csv'\n",
    "TARGET = 'SOP (S/N)'\n",
    "\n",
    "print(\"Cargando datasets...\")\n",
    "df_trees = pd.read_csv(PATH_DATASET_A)\n",
    "df_logit = pd.read_csv(PATH_DATASET_B)\n",
    "\n",
    "# Conversi√≥n a float64\n",
    "print(\"Convirtiendo a float64...\")\n",
    "for col in df_trees.columns:\n",
    "    if col != TARGET:\n",
    "        df_trees[col] = pd.to_numeric(df_trees[col], errors='coerce').fillna(0).astype(np.float64)\n",
    "\n",
    "for col in df_logit.columns:\n",
    "    if col != TARGET:\n",
    "        df_logit[col] = pd.to_numeric(df_logit[col], errors='coerce').fillna(0).astype(np.float64)\n",
    "\n",
    "print(f\"‚úì Dataset A: {df_trees.shape}\")\n",
    "print(f\"‚úì Dataset B: {df_logit.shape}\")\n",
    "print()\n",
    "\n",
    "# Guardar nombres de columnas\n",
    "feature_names_trees = df_trees.drop(TARGET, axis=1).columns.tolist()\n",
    "feature_names_logit = df_logit.drop(TARGET, axis=1).columns.tolist()\n",
    "\n",
    "# Convertir a arrays\n",
    "X_trees = df_trees.drop(TARGET, axis=1).values.astype(np.float64)\n",
    "y_trees = df_trees[TARGET].values.astype(np.int32)\n",
    "\n",
    "X_logit = df_logit.drop(TARGET, axis=1).values.astype(np.float64)\n",
    "y_logit = df_logit[TARGET].values.astype(np.int32)\n",
    "\n",
    "# Split\n",
    "X_train_trees, X_test_trees, y_train_trees, y_test_trees = train_test_split(\n",
    "    X_trees, y_trees, test_size=0.20, random_state=RANDOM_STATE, stratify=y_trees\n",
    ")\n",
    "\n",
    "X_train_logit, X_test_logit, y_train_logit, y_test_logit = train_test_split(\n",
    "    X_logit, y_logit, test_size=0.20, random_state=RANDOM_STATE, stratify=y_logit\n",
    ")\n",
    "\n",
    "# SMOTE\n",
    "print(\"Aplicando SMOTE...\")\n",
    "smote = SMOTE(random_state=RANDOM_STATE)\n",
    "\n",
    "X_train_trees_bal, y_train_trees_bal = smote.fit_resample(X_train_trees, y_train_trees)\n",
    "X_train_trees_bal = X_train_trees_bal.astype(np.float64)\n",
    "\n",
    "X_train_logit_bal, y_train_logit_bal = smote.fit_resample(X_train_logit, y_train_logit)\n",
    "X_train_logit_bal = X_train_logit_bal.astype(np.float64)\n",
    "\n",
    "# Escalamiento\n",
    "scaler_logit = StandardScaler()\n",
    "X_train_logit_scaled = scaler_logit.fit_transform(X_train_logit_bal).astype(np.float64)\n",
    "X_test_logit_scaled = scaler_logit.transform(X_test_logit).astype(np.float64)\n",
    "\n",
    "scaler_knn = StandardScaler()\n",
    "X_train_trees_scaled = scaler_knn.fit_transform(X_train_trees_bal).astype(np.float64)\n",
    "X_test_trees_scaled = scaler_knn.transform(X_test_trees).astype(np.float64)\n",
    "\n",
    "print(f\"‚úì Train={len(X_train_trees_bal)}, Test={len(X_test_trees)}\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 2: ENTRENAMIENTO DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 2: ENTRENAMIENTO DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print(\"1. Logistic Regression...\")\n",
    "lr_model = LogisticRegression(C=0.1, max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_model.fit(X_train_logit_scaled, y_train_logit_bal)\n",
    "y_pred_lr = lr_model.predict(X_test_logit_scaled)\n",
    "y_pred_proba_lr = lr_model.predict_proba(X_test_logit_scaled)[:, 1]\n",
    "\n",
    "# 2. Random Forest con RFE (30 features)\n",
    "print(\"2. Random Forest con RFE (30 features)...\")\n",
    "rf_base = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rfe = RFE(rf_base, n_features_to_select=30, step=1)\n",
    "rfe.fit(X_train_trees_bal, y_train_trees_bal)\n",
    "\n",
    "X_train_rf = rfe.transform(X_train_trees_bal).astype(np.float64)\n",
    "X_test_rf = rfe.transform(X_test_trees).astype(np.float64)\n",
    "\n",
    "selected_features = [feature_names_trees[i] for i, sel in enumerate(rfe.support_) if sel]\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=10, min_samples_split=5, \n",
    "    min_samples_leaf=1, random_state=RANDOM_STATE\n",
    ")\n",
    "rf_model.fit(X_train_rf, y_train_trees_bal)\n",
    "y_pred_rf = rf_model.predict(X_test_rf)\n",
    "y_pred_proba_rf = rf_model.predict_proba(X_test_rf)[:, 1]\n",
    "\n",
    "# 3. XGBoost (con las mismas 30 features que RF)\n",
    "print(\"3. XGBoost (30 features)...\")\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "    subsample=0.8, random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', base_score=0.5, use_label_encoder=False\n",
    ")\n",
    "xgb_model.fit(X_train_rf, y_train_trees_bal)\n",
    "y_pred_xgb = xgb_model.predict(X_test_rf)\n",
    "y_pred_proba_xgb = xgb_model.predict_proba(X_test_rf)[:, 1]\n",
    "\n",
    "# 3b. XGBoost COMPLETO (41 features) - solo para SHAP\n",
    "print(\"3b. XGBoost completo (41 features, solo para SHAP)...\")\n",
    "xgb_model_full = xgb.XGBClassifier(\n",
    "    learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "    subsample=0.8, random_state=RANDOM_STATE, \n",
    "    eval_metric='logloss', base_score=0.5, use_label_encoder=False\n",
    ")\n",
    "xgb_model_full.fit(X_train_trees_bal.astype(np.float64), y_train_trees_bal)\n",
    "y_pred_xgb_full = xgb_model_full.predict(X_test_trees)\n",
    "y_pred_proba_xgb_full = xgb_model_full.predict_proba(X_test_trees)[:, 1]\n",
    "\n",
    "# 4. KNN\n",
    "print(\"4. K-Nearest Neighbors...\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=7, weights='distance', metric='manhattan')\n",
    "knn_model.fit(X_train_trees_scaled, y_train_trees_bal)\n",
    "y_pred_knn = knn_model.predict(X_test_trees_scaled)\n",
    "y_pred_proba_knn = knn_model.predict_proba(X_test_trees_scaled)[:, 1]\n",
    "\n",
    "print(\"‚úì Modelos entrenados\")\n",
    "print()\n",
    "print(\"NOTA: Ensemble eliminado (causa conflictos sklearn/xgboost y no mejora resultados)\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 3: M√âTRICAS CL√çNICAS EXTENDIDAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 3: M√âTRICAS CL√çNICAS EXTENDIDAS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "def calcular_metricas_clinicas(y_true, y_pred, y_pred_proba, model_name):\n",
    "    \"\"\"Calcula m√©tricas cl√≠nicas completas\"\"\"\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sensibilidad = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    especificidad = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    lr_pos = sensibilidad / (1 - especificidad) if especificidad < 1 else np.inf\n",
    "    lr_neg = (1 - sensibilidad) / especificidad if especificidad > 0 else np.inf\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'TN': int(tn), 'FP': int(fp), 'FN': int(fn), 'TP': int(tp),\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision (PPV)': ppv,\n",
    "        'Recall (Sensibilidad)': sensibilidad,\n",
    "        'Especificidad': especificidad,\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'NPV': npv,\n",
    "        'LR+': lr_pos,\n",
    "        'LR-': lr_neg,\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_pred_proba)\n",
    "    }\n",
    "\n",
    "metricas_clinicas = []\n",
    "metricas_clinicas.append(calcular_metricas_clinicas(y_test_logit, y_pred_lr, y_pred_proba_lr, 'Logistic Regression'))\n",
    "metricas_clinicas.append(calcular_metricas_clinicas(y_test_trees, y_pred_rf, y_pred_proba_rf, 'Random Forest (30f)'))\n",
    "metricas_clinicas.append(calcular_metricas_clinicas(y_test_trees, y_pred_xgb_full, y_pred_proba_xgb_full, 'XGBoost (41f)'))\n",
    "metricas_clinicas.append(calcular_metricas_clinicas(y_test_trees, y_pred_xgb, y_pred_proba_xgb, 'XGBoost (30f)'))\n",
    "metricas_clinicas.append(calcular_metricas_clinicas(y_test_trees, y_pred_knn, y_pred_proba_knn, 'KNN'))\n",
    "\n",
    "df_clinicas = pd.DataFrame(metricas_clinicas)\n",
    "print(df_clinicas.to_string(index=False))\n",
    "print()\n",
    "\n",
    "df_clinicas.to_csv('metricas_clinicas_extendidas.csv', index=False)\n",
    "print(\"‚úì Guardado: metricas_clinicas_extendidas.csv\")\n",
    "print()\n",
    "\n",
    "print(\"NOTA: XGBoost evaluado con 41 features (completo) y 30 features (RFE)\")\n",
    "print()\n",
    "\n",
    "print(\"INTERPRETACI√ìN CL√çNICA:\")\n",
    "print()\n",
    "print(\"Sensibilidad (Recall): % de casos SOP detectados correctamente\")\n",
    "print(\"  ‚Üí Alto = Menos falsos negativos (no se pierden casos)\")\n",
    "print()\n",
    "print(\"Especificidad: % de No-SOP identificados correctamente\")\n",
    "print(\"  ‚Üí Alto = Menos falsos positivos (menos alarmas falsas)\")\n",
    "print()\n",
    "print(\"PPV (Precision): Si predice SOP, ¬øprobabilidad real?\")\n",
    "print(\"  ‚Üí Alto = Predicci√≥n SOP confiable\")\n",
    "print()\n",
    "print(\"NPV: Si predice No-SOP, ¬øprobabilidad real?\")\n",
    "print(\"  ‚Üí Alto = Predicci√≥n negativa confiable\")\n",
    "print()\n",
    "print(\"LR+ (Likelihood Ratio +): >10 excelente, >5 muy bueno\")\n",
    "print(\"LR- (Likelihood Ratio -): <0.1 excelente, <0.2 muy bueno\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 4: SHAP EXPLICABILIDAD\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 4: SHAP EXPLICABILIDAD\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "if not SHAP_OK:\n",
    "    print(\"‚ö†Ô∏è SHAP no disponible\")\n",
    "    print(\"   Instalar: pip install shap --break-system-packages\")\n",
    "    print()\n",
    "else:\n",
    "    try:\n",
    "        # XGBoost SHAP (con 41 features completas)\n",
    "        print(\"Calculando SHAP para XGBoost (41 features)...\")\n",
    "        print(\"(Esto puede tardar 2-3 minutos)\")\n",
    "        print()\n",
    "        \n",
    "        X_test_trees_clean = X_test_trees.astype(np.float64)\n",
    "        \n",
    "        explainer_xgb = shap.TreeExplainer(xgb_model_full)\n",
    "        shap_values_xgb = explainer_xgb.shap_values(X_test_trees_clean)\n",
    "        \n",
    "        # Summary plot (barras)\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_xgb, X_test_trees_clean,\n",
    "                         feature_names=feature_names_trees,\n",
    "                         plot_type=\"bar\", show=False, max_display=15)\n",
    "        plt.title('XGBoost - Top 15 Variables Importantes (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_xgboost_summary.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì shap_xgboost_summary.png\")\n",
    "        \n",
    "        # Beeswarm plot\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_xgb, X_test_trees_clean,\n",
    "                         feature_names=feature_names_trees,\n",
    "                         show=False, max_display=15)\n",
    "        plt.title('XGBoost - Distribuci√≥n de Impacto (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_xgboost_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì shap_xgboost_beeswarm.png\")\n",
    "        \n",
    "        # Tabla importancia\n",
    "        shap_importance_xgb = pd.DataFrame({\n",
    "            'Feature': feature_names_trees,\n",
    "            'SHAP_Mean_Abs': np.abs(shap_values_xgb).mean(axis=0)\n",
    "        }).sort_values('SHAP_Mean_Abs', ascending=False)\n",
    "        \n",
    "        shap_importance_xgb.to_csv('shap_importance_xgboost.csv', index=False)\n",
    "        print(\"‚úì shap_importance_xgboost.csv\")\n",
    "        print()\n",
    "        \n",
    "        print(\"TOP 10 VARIABLES (XGBoost SHAP):\")\n",
    "        print(shap_importance_xgb.head(10).to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        # Random Forest SHAP\n",
    "        print(\"Calculando SHAP para Random Forest...\")\n",
    "        print(\"(Esto puede tardar 3-5 minutos)\")\n",
    "        print()\n",
    "        \n",
    "        explainer_rf = shap.TreeExplainer(rf_model)\n",
    "        shap_values_rf = explainer_rf.shap_values(X_test_rf)\n",
    "        \n",
    "        if isinstance(shap_values_rf, list):\n",
    "            shap_values_rf = shap_values_rf[1]\n",
    "        \n",
    "        # Summary plot RF\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_rf, X_test_rf,\n",
    "                         feature_names=selected_features,\n",
    "                         plot_type=\"bar\", show=False, max_display=15)\n",
    "        plt.title('Random Forest (30f) - Top 15 Variables (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_rf_summary.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì shap_rf_summary.png\")\n",
    "        \n",
    "        # Beeswarm RF\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_rf, X_test_rf,\n",
    "                         feature_names=selected_features,\n",
    "                         show=False, max_display=15)\n",
    "        plt.title('Random Forest (30f) - Distribuci√≥n de Impacto (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_rf_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"‚úì shap_rf_beeswarm.png\")\n",
    "        \n",
    "        # Tabla importancia RF\n",
    "        shap_importance_rf = pd.DataFrame({\n",
    "            'Feature': selected_features,\n",
    "            'SHAP_Mean_Abs': np.abs(shap_values_rf).mean(axis=0)\n",
    "        }).sort_values('SHAP_Mean_Abs', ascending=False)\n",
    "        \n",
    "        shap_importance_rf.to_csv('shap_importance_rf.csv', index=False)\n",
    "        print(\"‚úì shap_importance_rf.csv\")\n",
    "        print()\n",
    "        \n",
    "        print(\"TOP 10 VARIABLES (Random Forest SHAP):\")\n",
    "        print(shap_importance_rf.head(10).to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        print(\"‚úÖ SHAP completado exitosamente\")\n",
    "        print()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en SHAP: {e}\")\n",
    "        print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 5: COMPARACI√ìN DE MODELOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 5: COMPARACI√ìN DE MODELOS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "comparison_data = []\n",
    "for name, y_pred, y_proba, y_true in [\n",
    "    ('Logistic Regression', y_pred_lr, y_pred_proba_lr, y_test_logit),\n",
    "    ('Random Forest (30f)', y_pred_rf, y_pred_proba_rf, y_test_trees),\n",
    "    ('XGBoost (41f)', y_pred_xgb_full, y_pred_proba_xgb_full, y_test_trees),\n",
    "    ('XGBoost (30f)', y_pred_xgb, y_pred_proba_xgb, y_test_trees),\n",
    "    ('KNN', y_pred_knn, y_pred_proba_knn, y_test_trees)\n",
    "]:\n",
    "    comparison_data.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_true, y_pred),\n",
    "        'Precision': precision_score(y_true, y_pred),\n",
    "        'Recall': recall_score(y_true, y_pred),\n",
    "        'F1-Score': f1_score(y_true, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_true, y_proba)\n",
    "    })\n",
    "\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "print(df_comparison.to_string(index=False))\n",
    "print()\n",
    "\n",
    "df_comparison.to_csv('modelos_comparison.csv', index=False)\n",
    "print(\"‚úì Guardado: modelos_comparison.csv\")\n",
    "print()\n",
    "\n",
    "# Identificar mejor modelo en test\n",
    "best_model_test = df_comparison.loc[df_comparison['F1-Score'].idxmax(), 'Model']\n",
    "best_f1_test = df_comparison['F1-Score'].max()\n",
    "\n",
    "print(f\"üèÜ MEJOR MODELO EN TEST SET: {best_model_test} (F1={best_f1_test:.4f})\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 6: VALIDACI√ìN CRUZADA REPETIDA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 6: VALIDACI√ìN CRUZADA REPETIDA (5√ó3)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"Configuraci√≥n: 5-Fold √ó 3 repeticiones = 15 evaluaciones\")\n",
    "print(\"(Esto puede tardar 5-10 minutos)\")\n",
    "print()\n",
    "\n",
    "repeated_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=RANDOM_STATE)\n",
    "\n",
    "scoring = {\n",
    "    'accuracy': 'accuracy',\n",
    "    'precision': 'precision',\n",
    "    'recall': 'recall',\n",
    "    'f1': 'f1',\n",
    "    'roc_auc': 'roc_auc'\n",
    "}\n",
    "\n",
    "modelos_validacion = {\n",
    "    'Logistic Regression': (lr_model, X_train_logit_scaled, y_train_logit_bal),\n",
    "    'Random Forest (30f)': (rf_model, X_train_rf, y_train_trees_bal),\n",
    "    'XGBoost (30f)': (xgb_model, X_train_rf, y_train_trees_bal),\n",
    "    'KNN': (knn_model, X_train_trees_scaled, y_train_trees_bal)\n",
    "}\n",
    "\n",
    "resultados_validacion = []\n",
    "\n",
    "for model_name, (model, X_train, y_train) in modelos_validacion.items():\n",
    "    print(f\"Validando {model_name}...\")\n",
    "    \n",
    "    cv_results = cross_validate(\n",
    "        model, X_train, y_train,\n",
    "        cv=repeated_cv,\n",
    "        scoring=scoring,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    resultados_validacion.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy_mean': cv_results['test_accuracy'].mean(),\n",
    "        'Accuracy_std': cv_results['test_accuracy'].std(),\n",
    "        'Precision_mean': cv_results['test_precision'].mean(),\n",
    "        'Precision_std': cv_results['test_precision'].std(),\n",
    "        'Recall_mean': cv_results['test_recall'].mean(),\n",
    "        'Recall_std': cv_results['test_recall'].std(),\n",
    "        'F1_mean': cv_results['test_f1'].mean(),\n",
    "        'F1_std': cv_results['test_f1'].std(),\n",
    "        'ROC_AUC_mean': cv_results['test_roc_auc'].mean(),\n",
    "        'ROC_AUC_std': cv_results['test_roc_auc'].std()\n",
    "    })\n",
    "    \n",
    "    print(f\"  ‚úì F1 = {cv_results['test_f1'].mean():.4f} ¬± {cv_results['test_f1'].std():.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "df_validacion = pd.DataFrame(resultados_validacion)\n",
    "print(\"RESULTADOS VALIDACI√ìN CRUZADA REPETIDA:\")\n",
    "print()\n",
    "print(df_validacion.to_string(index=False))\n",
    "print()\n",
    "\n",
    "df_validacion.to_csv('validacion_repetida_results.csv', index=False)\n",
    "print(\"‚úì Guardado: validacion_repetida_results.csv\")\n",
    "print()\n",
    "\n",
    "# Visualizaci√≥n intervalos de confianza\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "models = df_validacion['Model'].values\n",
    "f1_means = df_validacion['F1_mean'].values\n",
    "f1_stds = df_validacion['F1_std'].values\n",
    "\n",
    "y_pos = np.arange(len(models))\n",
    "\n",
    "ax.barh(y_pos, f1_means, xerr=f1_stds, align='center', alpha=0.7, \n",
    "        capsize=5, color='steelblue', ecolor='darkblue')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(models)\n",
    "ax.invert_yaxis()\n",
    "ax.set_xlabel('F1-Score (media ¬± std)', fontsize=12, fontweight='bold')\n",
    "ax.set_title('Validaci√≥n Cruzada Repetida - F1-Score con Intervalos de Confianza', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('validacion_repetida_intervals.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(\"‚úì Guardado: validacion_repetida_intervals.png\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SECCI√ìN 7: REPORTE FINAL Y RECOMENDACIONES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"REPORTE FINAL Y RECOMENDACIONES\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Identificar mejor modelo\n",
    "best_model_idx = df_validacion['F1_mean'].idxmax()\n",
    "best_model_name = df_validacion.loc[best_model_idx, 'Model']\n",
    "best_f1_mean = df_validacion.loc[best_model_idx, 'F1_mean']\n",
    "best_f1_std = df_validacion.loc[best_model_idx, 'F1_std']\n",
    "\n",
    "print(f\"üèÜ MODELO RECOMENDADO:\")\n",
    "print(f\"   {best_model_name}\")\n",
    "print(f\"   F1-Score: {best_f1_mean:.4f} ¬± {best_f1_std:.4f}\")\n",
    "print()\n",
    "\n",
    "# Obtener m√©tricas del mejor modelo\n",
    "best_metrics = [m for m in metricas_clinicas if m['Model'] == best_model_name][0]\n",
    "\n",
    "print(\"üìä M√âTRICAS CL√çNICAS (Test Set):\")\n",
    "print(f\"   Sensibilidad: {best_metrics['Recall (Sensibilidad)']:.1%}\")\n",
    "print(f\"   Especificidad: {best_metrics['Especificidad']:.1%}\")\n",
    "print(f\"   PPV: {best_metrics['Precision (PPV)']:.1%}\")\n",
    "print(f\"   NPV: {best_metrics['NPV']:.1%}\")\n",
    "print(f\"   LR+: {best_metrics['LR+']:.2f}\")\n",
    "print(f\"   LR-: {best_metrics['LR-']:.3f}\")\n",
    "print()\n",
    "\n",
    "print(\"üìã RECOMENDACIONES PARA TESIS/PAPER:\")\n",
    "print()\n",
    "print(\"1. MODELO FINAL:\")\n",
    "print(f\"   ‚Üí Usar {best_model_name}\")\n",
    "print(f\"   ‚Üí Reportar F1 = {best_f1_mean:.4f} ¬± {best_f1_std:.4f}\")\n",
    "print(f\"   ‚Üí Mencionar validaci√≥n cruzada repetida 5√ó3\")\n",
    "print()\n",
    "\n",
    "print(\"2. M√âTRICAS CL√çNICAS A REPORTAR:\")\n",
    "print(f\"   ‚Üí Sensibilidad: {best_metrics['Recall (Sensibilidad)']:.1%} (detecta casos SOP)\")\n",
    "print(f\"   ‚Üí Especificidad: {best_metrics['Especificidad']:.1%} (identifica No-SOP)\")\n",
    "print(f\"   ‚Üí PPV: {best_metrics['Precision (PPV)']:.1%} (confianza predicci√≥n positiva)\")\n",
    "print(f\"   ‚Üí NPV: {best_metrics['NPV']:.1%} (confianza predicci√≥n negativa)\")\n",
    "print()\n",
    "\n",
    "print(\"3. EXPLICABILIDAD:\")\n",
    "if SHAP_OK:\n",
    "    print(\"   ‚Üí Usar gr√°ficos SHAP beeswarm para interpretaci√≥n\")\n",
    "    print(\"   ‚Üí Discutir top 5-10 variables m√°s importantes\")\n",
    "    print(\"   ‚Üí Validar coherencia cl√≠nica con criterios Rotterdam\")\n",
    "else:\n",
    "    print(\"   ‚Üí Instalar SHAP para generar gr√°ficos de explicabilidad\")\n",
    "print()\n",
    "\n",
    "print(\"4. VALIDACI√ìN:\")\n",
    "print(\"   ‚Üí Mencionar robustez (validaci√≥n repetida 15 evaluaciones)\")\n",
    "print(\"   ‚Üí Reportar intervalos de confianza\")\n",
    "print(\"   ‚Üí Destacar reducci√≥n dimensional (42 ‚Üí 30 features)\")\n",
    "print()\n",
    "\n",
    "# Guardar reporte JSON\n",
    "reporte_final = {\n",
    "    'fecha_analisis': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'modelo_recomendado': {\n",
    "        'nombre': best_model_name,\n",
    "        'f1_score': {'mean': float(best_f1_mean), 'std': float(best_f1_std)},\n",
    "        'validacion': 'Repeated Stratified K-Fold (5√ó3)'\n",
    "    },\n",
    "    'metricas_clinicas_test': {\n",
    "        'sensibilidad': float(best_metrics['Recall (Sensibilidad)']),\n",
    "        'especificidad': float(best_metrics['Especificidad']),\n",
    "        'ppv': float(best_metrics['Precision (PPV)']),\n",
    "        'npv': float(best_metrics['NPV']),\n",
    "        'lr_plus': float(best_metrics['LR+']),\n",
    "        'lr_minus': float(best_metrics['LR-']),\n",
    "        'accuracy': float(best_metrics['Accuracy']),\n",
    "        'roc_auc': float(best_metrics['ROC-AUC'])\n",
    "    },\n",
    "    'confusion_matrix_test': {\n",
    "        'TN': int(best_metrics['TN']),\n",
    "        'FP': int(best_metrics['FP']),\n",
    "        'FN': int(best_metrics['FN']),\n",
    "        'TP': int(best_metrics['TP'])\n",
    "    },\n",
    "    'features': {\n",
    "        'originales': len(feature_names_trees),\n",
    "        'seleccionadas_rf': 30 if 'RF' in best_model_name or 'Ensemble' in best_model_name else len(feature_names_trees),\n",
    "        'metodo_seleccion': 'RFE' if 'RF' in best_model_name else 'None'\n",
    "    },\n",
    "    'comparacion_modelos': df_comparison.to_dict('records'),\n",
    "    'validacion_cruzada': df_validacion.to_dict('records')\n",
    "}\n",
    "\n",
    "with open('reporte_final_paso10.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(reporte_final, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "print(\"‚úì Reporte guardado: reporte_final_paso10.json\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# ARCHIVOS GENERADOS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"ARCHIVOS GENERADOS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"üìÅ M√âTRICAS Y RESULTADOS:\")\n",
    "print(\"  1. metricas_clinicas_extendidas.csv\")\n",
    "print(\"  2. modelos_comparison.csv\")\n",
    "print(\"  3. validacion_repetida_results.csv\")\n",
    "if SHAP_OK:\n",
    "    print(\"  4. shap_importance_xgboost.csv\")\n",
    "    print(\"  5. shap_importance_rf.csv\")\n",
    "print()\n",
    "\n",
    "print(\"üìä VISUALIZACIONES:\")\n",
    "if SHAP_OK:\n",
    "    print(\"  6. shap_xgboost_summary.png\")\n",
    "    print(\"  7. shap_xgboost_beeswarm.png\")\n",
    "    print(\"  8. shap_rf_summary.png\")\n",
    "    print(\"  9. shap_rf_beeswarm.png\")\n",
    "print(\"  10. validacion_repetida_intervals.png\")\n",
    "print()\n",
    "\n",
    "print(\"üìÑ REPORTES:\")\n",
    "print(\"  11. reporte_final_paso10.json\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# FINALIZACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ PASO 10 COMPLETADO EXITOSAMENTE\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "print(\"üéâ AN√ÅLISIS COMPLETO Y VALIDADO\")\n",
    "print()\n",
    "print(\"Has completado:\")\n",
    "print(\"  ‚úì M√©tricas cl√≠nicas extendidas (Sens/Spec/PPV/NPV/LR)\")\n",
    "print(\"  ‚úì Explicabilidad SHAP (XGBoost + Random Forest)\")\n",
    "print(\"  ‚úì Comparaci√≥n completa de modelos\")\n",
    "print(\"  ‚úì Validaci√≥n cruzada repetida (robustez demostrada)\")\n",
    "print(\"  ‚úì Reporte final completo\")\n",
    "print()\n",
    "print(\"Tu proyecto est√° listo para:\")\n",
    "print(\"  ‚Üí Defensa de tesis ‚úÖ\")\n",
    "print(\"  ‚Üí Publicaci√≥n cient√≠fica ‚úÖ\")\n",
    "print(\"  ‚Üí Presentaci√≥n a comit√© biom√©dico ‚úÖ\")\n",
    "print()\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a67e8dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECCI√ìN 5B: GR√ÅFICO COMPARATIVO ROC-AUC\n",
      "================================================================================\n",
      "\n",
      "‚úì Guardado: roc_curves_comparativa1.png\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NUEVA SECCI√ìN: GR√ÅFICO COMPARATIVO ROC-AUC\n",
    "# =============================================================================\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN 5B: GR√ÅFICO COMPARATIVO ROC-AUC\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Calcular puntos de la curva para cada modelo\n",
    "# (Usamos y_test_logit para LR, y_test_trees para los dem√°s)\n",
    "fpr_lr, tpr_lr, _ = roc_curve(y_test_logit, y_pred_proba_lr)\n",
    "auc_lr = roc_auc_score(y_test_logit, y_pred_proba_lr)\n",
    "\n",
    "fpr_rf, tpr_rf, _ = roc_curve(y_test_trees, y_pred_proba_rf)\n",
    "auc_rf = roc_auc_score(y_test_trees, y_pred_proba_rf)\n",
    "\n",
    "fpr_xgb, tpr_xgb, _ = roc_curve(y_test_trees, y_pred_proba_xgb)\n",
    "auc_xgb = roc_auc_score(y_test_trees, y_pred_proba_xgb)\n",
    "\n",
    "fpr_knn, tpr_knn, _ = roc_curve(y_test_trees, y_pred_proba_knn)\n",
    "auc_knn = roc_auc_score(y_test_trees, y_pred_proba_knn)\n",
    "\n",
    "# Iniciar el gr√°fico\n",
    "plt.figure(figsize=(18, 12))\n",
    "\n",
    "# Graficar cada curva\n",
    "plt.plot(fpr_lr, tpr_lr, label=f'Logistic Regression (AUC = {auc_lr:.3f})', linewidth=2)\n",
    "plt.plot(fpr_rf, tpr_rf, label=f'Random Forest 30f (AUC = {auc_rf:.3f})', linewidth=2)\n",
    "plt.plot(fpr_xgb, tpr_xgb, label=f'XGBoost 30f (AUC = {auc_xgb:.3f})', linewidth=2)\n",
    "plt.plot(fpr_knn, tpr_knn, label=f'KNN (AUC = {auc_knn:.3f})', linewidth=2, linestyle=':')\n",
    "\n",
    "# Graficar la l√≠nea de no-habilidad (chance)\n",
    "plt.plot([0, 1], [0, 1], 'k--', label='Azar (AUC = 0.500)')\n",
    "\n",
    "# Estilo\n",
    "plt.xlabel('Tasa de Falsos Positivos (1 - Especificidad)', fontsize=12)\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (Sensibilidad)', fontsize=12)\n",
    "plt.title('Comparaci√≥n de Curvas ROC (Test Set)', fontsize=16, fontweight='bold')\n",
    "plt.legend(loc='lower right', fontsize=11)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Guardar el gr√°fico\n",
    "plt.savefig('roc_curves_comparativa1.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"‚úì Guardado: roc_curves_comparativa1.png\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c37e5e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "SECCI√ìN X: MATRIZ DE CONFUSI√ìN DEL MEJOR MODELO\n",
      "================================================================================\n",
      "\n",
      "‚úì Guardado: confusion_matrix_best_model.png para XGBoost (41f) - Test Set\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# NUEVA SECCI√ìN: MATRIZ DE CONFUSI√ìN DEL MEJOR MODELO\n",
    "# =============================================================================\n",
    "\n",
    "print()\n",
    "print(\"=\"*80)\n",
    "print(\"SECCI√ìN X: MATRIZ DE CONFUSI√ìN DEL MEJOR MODELO\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# Identificar el mejor modelo para la matriz de confusi√≥n\n",
    "# Seg√∫n tu output, el mejor modelo en validaci√≥n es Random Forest (30f)\n",
    "# Necesitamos sus predicciones y la y_test correspondiente\n",
    "\n",
    "# Obtener los datos del mejor modelo (Random Forest 30f)\n",
    "# y_pred_best_model = y_pred_rf\n",
    "# y_test_best_model = y_test_trees\n",
    "# best_model_name_for_cm = 'Random Forest (30f)'\n",
    "\n",
    "# O si quieres usar el que tuvo mejor F1 en el test set (XGBoost 41f), aunque en CV no fue el mejor\n",
    "y_pred_best_model = y_pred_xgb_full\n",
    "y_test_best_model = y_test_trees\n",
    "best_model_name_for_cm = 'XGBoost (41f) - Test Set'\n",
    "\n",
    "\n",
    "cm = confusion_matrix(y_test_best_model, y_pred_best_model)\n",
    "\n",
    "plt.figure(figsize=(7, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
    "            xticklabels=['No SOP', 'SOP'], yticklabels=['No SOP', 'SOP'],\n",
    "            linewidths=0.5, linecolor='black')\n",
    "plt.xlabel('Predicci√≥n', fontsize=12, fontweight='bold')\n",
    "plt.ylabel('Real', fontsize=12, fontweight='bold')\n",
    "plt.title(f'Matriz de Confusi√≥n: {best_model_name_for_cm}', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_best_model.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"‚úì Guardado: confusion_matrix_best_model.png para {best_model_name_for_cm}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0ca01850",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando gr√°fico SHAP para una predicci√≥n individual (XGBoost)...\n",
      "‚úì shap_xgboost_force_plot_sample_0.png\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1200x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==========================================================\n",
    "# SHAP: Fuerza para una predicci√≥n individual (XGBoost)\n",
    "# ==========================================================\n",
    "print(\"Generando gr√°fico SHAP para una predicci√≥n individual (XGBoost)...\")\n",
    "\n",
    "# Elige un √≠ndice de ejemplo. Por ejemplo, la primera paciente del test set.\n",
    "# Puedes cambiar este √≠ndice (por ejemplo, 5, 10, etc.)\n",
    "sample_idx = 0 \n",
    "\n",
    "# Obtener el valor SHAP base (expected_value) y los shap_values para el ejemplo\n",
    "# Nota: 'explainer_xgb' se cre√≥ en la secci√≥n anterior de SHAP para XGBoost\n",
    "expected_value_xgb = explainer_xgb.expected_value\n",
    "\n",
    "# Asegurarnos de que estamos usando los datos correctos (NumPy array)\n",
    "# X_test_trees ya es un array de NumPy limpio en este punto del script corregido\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "shap.force_plot(expected_value_xgb, \n",
    "                shap_values_xgb[sample_idx,:], \n",
    "                X_test_trees[sample_idx,:], \n",
    "                feature_names=feature_names_trees, \n",
    "                matplotlib=True, show=False)\n",
    "plt.title(f'SHAP: Predicci√≥n Individual (Paciente {sample_idx}, XGBoost)', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'shap_xgboost_force_plot_sample_{sample_idx}.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"‚úì shap_xgboost_force_plot_sample_{sample_idx}.png\")\n",
    "print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
