{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d637dd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "PASO 10 - VERSI√ìN DEFINITIVA CON LIMPIEZA ULTRA AGRESIVA\n",
    "\"\"\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix\n",
    ")\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "try:\n",
    "    import shap\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SHAP_AVAILABLE = False\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"PASO 10 - VERSI√ìN CON LIMPIEZA ULTRA AGRESIVA\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# FUNCI√ìN DE LIMPIEZA ULTRA AGRESIVA\n",
    "# =============================================================================\n",
    "\n",
    "def limpiar_ultra_agresivo(X):\n",
    "    \"\"\"Convierte TODO a float64, eliminando strings '[5E-1]'\"\"\"\n",
    "    \n",
    "    # Si es DataFrame\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_clean = X.copy()\n",
    "        for col in X_clean.columns:\n",
    "            if X_clean[col].dtype == 'object':\n",
    "                X_clean[col] = X_clean[col].astype(str).str.replace('[', '').str.replace(']', '')\n",
    "                X_clean[col] = pd.to_numeric(X_clean[col], errors='coerce').fillna(0)\n",
    "        return X_clean.values.astype(np.float64)\n",
    "    \n",
    "    # Si es numpy array con dtype object\n",
    "    elif isinstance(X, np.ndarray):\n",
    "        if X.dtype == 'object':\n",
    "            X_temp = []\n",
    "            for row in X:\n",
    "                row_clean = []\n",
    "                for val in row:\n",
    "                    if isinstance(val, str):\n",
    "                        val_clean = val.replace('[', '').replace(']', '')\n",
    "                        try:\n",
    "                            row_clean.append(float(val_clean))\n",
    "                        except:\n",
    "                            row_clean.append(0.0)\n",
    "                    else:\n",
    "                        try:\n",
    "                            row_clean.append(float(val))\n",
    "                        except:\n",
    "                            row_clean.append(0.0)\n",
    "                X_temp.append(row_clean)\n",
    "            return np.array(X_temp, dtype=np.float64)\n",
    "        else:\n",
    "            return X.astype(np.float64)\n",
    "    \n",
    "    return X\n",
    "\n",
    "# =============================================================================\n",
    "# CARGA Y LIMPIEZA INICIAL\n",
    "# =============================================================================\n",
    "\n",
    "PATH_DATASET_A = '../documentos_generados/PCOS_data_transformado.csv'\n",
    "PATH_DATASET_B = 'PCOS_data_FINAL_sin_multicolinealidad.csv'\n",
    "TARGET_COL = 'SOP (S/N)'\n",
    "\n",
    "print(\"Cargando y limpiando datasets...\")\n",
    "df_trees = pd.read_csv(PATH_DATASET_A)\n",
    "df_logit = pd.read_csv(PATH_DATASET_B)\n",
    "\n",
    "# LIMPIEZA INMEDIATA\n",
    "for col in df_trees.columns:\n",
    "    if col != TARGET_COL and df_trees[col].dtype == 'object':\n",
    "        df_trees[col] = df_trees[col].astype(str).str.replace('[', '').str.replace(']', '')\n",
    "        df_trees[col] = pd.to_numeric(df_trees[col], errors='coerce').fillna(0)\n",
    "\n",
    "for col in df_logit.columns:\n",
    "    if col != TARGET_COL and df_logit[col].dtype == 'object':\n",
    "        df_logit[col] = df_logit[col].astype(str).str.replace('[', '').str.replace(']', '')\n",
    "        df_logit[col] = pd.to_numeric(df_logit[col], errors='coerce').fillna(0)\n",
    "\n",
    "print(f\"‚úì Dataset A: {df_trees.shape}\")\n",
    "print(f\"‚úì Dataset B: {df_logit.shape}\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# PREPARACI√ìN\n",
    "# =============================================================================\n",
    "\n",
    "X_trees = df_trees.drop(TARGET_COL, axis=1)\n",
    "y_trees = df_trees[TARGET_COL]\n",
    "X_logit = df_logit.drop(TARGET_COL, axis=1)\n",
    "y_logit = df_logit[TARGET_COL]\n",
    "\n",
    "X_train_trees, X_test_trees, y_train_trees, y_test_trees = train_test_split(\n",
    "    X_trees, y_trees, test_size=0.20, random_state=RANDOM_STATE, stratify=y_trees\n",
    ")\n",
    "\n",
    "X_train_logit, X_test_logit, y_train_logit, y_test_logit = train_test_split(\n",
    "    X_logit, y_logit, test_size=0.20, random_state=RANDOM_STATE, stratify=y_logit\n",
    ")\n",
    "\n",
    "smote_trees = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_trees_balanced, y_train_trees_balanced = smote_trees.fit_resample(X_train_trees, y_train_trees)\n",
    "\n",
    "smote_logit = SMOTE(random_state=RANDOM_STATE)\n",
    "X_train_logit_balanced, y_train_logit_balanced = smote_logit.fit_resample(X_train_logit, y_train_logit)\n",
    "\n",
    "scaler_logit = StandardScaler()\n",
    "X_train_logit_scaled = pd.DataFrame(\n",
    "    scaler_logit.fit_transform(X_train_logit_balanced),\n",
    "    columns=X_train_logit.columns\n",
    ")\n",
    "X_test_logit_scaled = pd.DataFrame(\n",
    "    scaler_logit.transform(X_test_logit),\n",
    "    columns=X_test_logit.columns\n",
    ")\n",
    "\n",
    "print(\"‚úì Datos preparados\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# M√âTRICAS CL√çNICAS\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 1: M√âTRICAS CL√çNICAS\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "def calcular_metricas_clinicas(y_true, y_pred, model_name):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    sens = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    spec = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    ppv = tp / (tp + fp) if (tp + fp) > 0 else 0\n",
    "    npv = tn / (tn + fn) if (tn + fn) > 0 else 0\n",
    "    \n",
    "    return {\n",
    "        'Model': model_name,\n",
    "        'TN': int(tn), 'FP': int(fp), 'FN': int(fn), 'TP': int(tp),\n",
    "        'Sensibilidad': sens,\n",
    "        'Especificidad': spec,\n",
    "        'PPV': ppv,\n",
    "        'NPV': npv,\n",
    "        'F1': f1_score(y_true, y_pred)\n",
    "    }\n",
    "\n",
    "# Modelos\n",
    "lr_model = LogisticRegression(C=0.1, max_iter=1000, random_state=RANDOM_STATE)\n",
    "lr_model.fit(X_train_logit_scaled, y_train_logit_balanced)\n",
    "y_pred_lr = lr_model.predict(X_test_logit_scaled)\n",
    "\n",
    "rf_estimator = RandomForestClassifier(n_estimators=100, random_state=RANDOM_STATE)\n",
    "rfe = RFE(estimator=rf_estimator, n_features_to_select=30, step=1)\n",
    "rfe.fit(X_train_trees_balanced, y_train_trees_balanced)\n",
    "\n",
    "X_train_rf = limpiar_ultra_agresivo(rfe.transform(X_train_trees_balanced))\n",
    "X_test_rf = limpiar_ultra_agresivo(rfe.transform(X_test_trees))\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=200, max_depth=10, min_samples_split=5, \n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "rf_model.fit(X_train_rf, y_train_trees_balanced)\n",
    "y_pred_rf = rf_model.predict(X_test_rf)\n",
    "\n",
    "# CR√çTICO: Limpiar datos ANTES de entrenar XGBoost\n",
    "X_train_trees_balanced_LIMPIO = limpiar_ultra_agresivo(X_train_trees_balanced)\n",
    "X_test_trees_LIMPIO = limpiar_ultra_agresivo(X_test_trees)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(\n",
    "    learning_rate=0.1, n_estimators=100, max_depth=5,\n",
    "    subsample=0.8, random_state=RANDOM_STATE, eval_metric='logloss',\n",
    "    base_score=0.5  # Forzar base_score v√°lido\n",
    ")\n",
    "xgb_model.fit(X_train_trees_balanced_LIMPIO, y_train_trees_balanced)\n",
    "y_pred_xgb = xgb_model.predict(X_test_trees_LIMPIO)\n",
    "\n",
    "print(\"‚úì Modelos entrenados\")\n",
    "print()\n",
    "\n",
    "metricas = []\n",
    "metricas.append(calcular_metricas_clinicas(y_test_logit, y_pred_lr, 'Logistic Regression'))\n",
    "metricas.append(calcular_metricas_clinicas(y_test_trees, y_pred_rf, 'Random Forest'))\n",
    "metricas.append(calcular_metricas_clinicas(y_test_trees, y_pred_xgb, 'XGBoost'))\n",
    "\n",
    "df_metricas = pd.DataFrame(metricas)\n",
    "print(df_metricas.to_string(index=False))\n",
    "print()\n",
    "\n",
    "df_metricas.to_csv('metricas_clinicas.csv', index=False)\n",
    "print(\"‚úì Guardado: metricas_clinicas.csv\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# SHAP CON LIMPIEZA ULTRA AGRESIVA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 2: SHAP (CON LIMPIEZA GARANTIZADA)\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "if not SHAP_AVAILABLE:\n",
    "    print(\"‚ö†Ô∏è SHAP no disponible\")\n",
    "else:\n",
    "    try:\n",
    "        print(\"Calculando SHAP para XGBoost...\")\n",
    "        \n",
    "        # Usar los datos ya limpios (X_test_trees_LIMPIO ya existe arriba)\n",
    "        print(f\"  Datos: dtype={X_test_trees_LIMPIO.dtype}, shape={X_test_trees_LIMPIO.shape}\")\n",
    "        \n",
    "        explainer_xgb = shap.TreeExplainer(xgb_model)\n",
    "        shap_values_xgb = explainer_xgb.shap_values(X_test_trees_LIMPIO)\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_xgb, X_test_trees_LIMPIO, plot_type=\"bar\", show=False, max_display=15)\n",
    "        plt.title('XGBoost - Top 15 Features (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_xgboost_summary.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ‚úì shap_xgboost_summary.png\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_xgb, X_test_trees_LIMPIO, show=False, max_display=15)\n",
    "        plt.title('XGBoost - Beeswarm (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_xgboost_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ‚úì shap_xgboost_beeswarm.png\")\n",
    "        \n",
    "        shap_imp = pd.DataFrame({\n",
    "            'Feature': X_test_trees.columns,\n",
    "            'SHAP_Mean_Abs': np.abs(shap_values_xgb).mean(axis=0)\n",
    "        }).sort_values('SHAP_Mean_Abs', ascending=False)\n",
    "        \n",
    "        shap_imp.to_csv('shap_importance_xgboost.csv', index=False)\n",
    "        print(\"  ‚úì shap_importance_xgboost.csv\")\n",
    "        print()\n",
    "        \n",
    "        print(\"TOP 10 FEATURES (XGBoost):\")\n",
    "        print(shap_imp.head(10).to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        # Random Forest\n",
    "        print(\"Calculando SHAP para Random Forest...\")\n",
    "        \n",
    "        # X_test_rf ya est√° limpio\n",
    "        explainer_rf = shap.TreeExplainer(rf_model)\n",
    "        shap_values_rf = explainer_rf.shap_values(X_test_rf)\n",
    "        \n",
    "        if isinstance(shap_values_rf, list):\n",
    "            shap_values_rf = shap_values_rf[1]\n",
    "        \n",
    "        selected_features = X_train_trees.columns[rfe.support_].tolist()\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_rf, X_test_rf, plot_type=\"bar\", show=False, max_display=15)\n",
    "        plt.title('Random Forest (30f) - Top 15 (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_rf_summary.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ‚úì shap_rf_summary.png\")\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        shap.summary_plot(shap_values_rf, X_test_rf, show=False, max_display=15)\n",
    "        plt.title('Random Forest (30f) - Beeswarm (SHAP)', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('shap_rf_beeswarm.png', dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        print(\"  ‚úì shap_rf_beeswarm.png\")\n",
    "        \n",
    "        shap_imp_rf = pd.DataFrame({\n",
    "            'Feature': selected_features,\n",
    "            'SHAP_Mean_Abs': np.abs(shap_values_rf).mean(axis=0)\n",
    "        }).sort_values('SHAP_Mean_Abs', ascending=False)\n",
    "        \n",
    "        shap_imp_rf.to_csv('shap_importance_rf.csv', index=False)\n",
    "        print(\"  ‚úì shap_importance_rf.csv\")\n",
    "        print()\n",
    "        \n",
    "        print(\"TOP 10 FEATURES (Random Forest):\")\n",
    "        print(shap_imp_rf.head(10).to_string(index=False))\n",
    "        print()\n",
    "        \n",
    "        print(\"‚úÖ SHAP COMPLETADO EXITOSAMENTE\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error en SHAP: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# VALIDACI√ìN REPETIDA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"FASE 3: VALIDACI√ìN REPETIDA\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "\n",
    "repeated_cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=RANDOM_STATE)\n",
    "\n",
    "modelos = {\n",
    "    'Logistic Regression': (lr_model, X_train_logit_scaled, y_train_logit_balanced),\n",
    "    'Random Forest (30f)': (rf_model, X_train_rf, y_train_trees_balanced),\n",
    "    'XGBoost': (xgb_model, X_train_trees_balanced_LIMPIO, y_train_trees_balanced)\n",
    "}\n",
    "\n",
    "resultados = []\n",
    "\n",
    "for name, (model, X, y) in modelos.items():\n",
    "    print(f\"Validando {name}...\")\n",
    "    cv_res = cross_validate(\n",
    "        model, X, y,\n",
    "        cv=repeated_cv,\n",
    "        scoring={'f1': 'f1', 'roc_auc': 'roc_auc'},\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    resultados.append({\n",
    "        'Model': name,\n",
    "        'F1_mean': cv_res['test_f1'].mean(),\n",
    "        'F1_std': cv_res['test_f1'].std(),\n",
    "        'AUC_mean': cv_res['test_roc_auc'].mean()\n",
    "    })\n",
    "    \n",
    "    print(f\"  ‚úì F1 = {cv_res['test_f1'].mean():.4f} ¬± {cv_res['test_f1'].std():.4f}\")\n",
    "\n",
    "print()\n",
    "\n",
    "df_val = pd.DataFrame(resultados)\n",
    "print(df_val.to_string(index=False))\n",
    "print()\n",
    "\n",
    "df_val.to_csv('validacion_repetida.csv', index=False)\n",
    "print(\"‚úì Guardado: validacion_repetida.csv\")\n",
    "print()\n",
    "\n",
    "# =============================================================================\n",
    "# REPORTE FINAL\n",
    "# =============================================================================\n",
    "\n",
    "best_idx = df_val['F1_mean'].idxmax()\n",
    "best_model = df_val.loc[best_idx, 'Model']\n",
    "best_f1 = df_val.loc[best_idx, 'F1_mean']\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"üèÜ MODELO RECOMENDADO\")\n",
    "print(\"=\"*80)\n",
    "print(f\"  {best_model}\")\n",
    "print(f\"  F1-Score: {best_f1:.4f}\")\n",
    "print()\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"‚úÖ PASO 10 COMPLETADO\")\n",
    "print(\"=\"*80)\n",
    "print()\n",
    "print(\"Archivos generados:\")\n",
    "print(\"  - metricas_clinicas.csv\")\n",
    "print(\"  - validacion_repetida.csv\")\n",
    "if SHAP_AVAILABLE:\n",
    "    print(\"  - shap_importance_xgboost.csv\")\n",
    "    print(\"  - shap_importance_rf.csv\")\n",
    "    print(\"  - shap_xgboost_summary.png\")\n",
    "    print(\"  - shap_xgboost_beeswarm.png\")\n",
    "    print(\"  - shap_rf_summary.png\")\n",
    "    print(\"  - shap_rf_beeswarm.png\")\n",
    "print()\n",
    "print(\"üéâ LISTO PARA DEFENSA/PUBLICACI√ìN\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
